{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Notebok for training the model"
      ],
      "metadata": {
        "id": "Ff_c8EhZWahq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Requirements"
      ],
      "metadata": {
        "id": "7K7oYB61o0au"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import rasterio\n",
        "from rasterio.mask import mask\n",
        "from rasterio import features\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import box\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import joblib\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n"
      ],
      "metadata": {
        "id": "jPBqFTSso7SG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Auxiliary Functions"
      ],
      "metadata": {
        "id": "5VLVHwKzo_fV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Here you will prepare, standardize, and analyze raster data for machine learning.**\n",
        "It includes creating labeled masks, selecting and padding bands, generating time-series data, and building corresponding label arrays.\n",
        "\n",
        "It also performs standard scaling, calculates classification metrics, and offers visualization tools."
      ],
      "metadata": {
        "id": "flNSn3UQSeKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_labeled_mask(gdf, reference_raster, output_path, id_column='Species_id'):\n",
        "    \"\"\"\n",
        "    Create and save a labeled (int32) mask from a shapefile.\n",
        "    \"\"\"\n",
        "    shapes = ((geom, value) for geom, value in zip(gdf.geometry, gdf[id_column]))\n",
        "    transform = reference_raster.transform\n",
        "    crs = reference_raster.crs\n",
        "    out_shape = (reference_raster.height, reference_raster.width)\n",
        "\n",
        "    mask_array = features.rasterize(\n",
        "        shapes=shapes,\n",
        "        out_shape=out_shape,\n",
        "        transform=transform,\n",
        "        fill=0,\n",
        "        all_touched=True,\n",
        "        dtype='int32',\n",
        "    )\n",
        "\n",
        "    with rasterio.open(\n",
        "        output_path,\n",
        "        'w',\n",
        "        driver='GTiff',\n",
        "        height=mask_array.shape[0],\n",
        "        width=mask_array.shape[1],\n",
        "        count=1,\n",
        "        dtype='int32',\n",
        "        crs=crs,\n",
        "        transform=transform,\n",
        "    ) as dst:\n",
        "        dst.write(mask_array, 1)\n",
        "\n",
        "\n",
        "def save_masked_image(output_path, stacked_bands, transform, crs):\n",
        "    \"\"\"\n",
        "    Save a multi-band raster (stacked_bands) as GeoTIFF.\n",
        "    \"\"\"\n",
        "    with rasterio.open(\n",
        "        output_path,\n",
        "        'w',\n",
        "        driver='GTiff',\n",
        "        height=stacked_bands.shape[1],\n",
        "        width=stacked_bands.shape[2],\n",
        "        count=stacked_bands.shape[0],\n",
        "        dtype='float32',\n",
        "        crs=crs,\n",
        "        transform=transform,\n",
        "    ) as dst:\n",
        "        for band_index in range(stacked_bands.shape[0]):\n",
        "            dst.write(stacked_bands[band_index, :, :], band_index + 1)\n",
        "\n",
        "\n",
        "def select_band_by_name(src, band_names, target_band_names):\n",
        "    \"\"\"\n",
        "    Select the desired bands (by name) from a raster opened with rasterio.\n",
        "    Returns a np.array with the selected bands.\n",
        "    \"\"\"\n",
        "    band_indices = [\n",
        "        band_names.index(target_band_name) + 1\n",
        "        for target_band_name in target_band_names\n",
        "        if target_band_name in band_names\n",
        "    ]\n",
        "    if not band_indices:\n",
        "        print(f\"None of the target bands found in {band_names}\")\n",
        "        return None\n",
        "    return src.read(band_indices)\n",
        "\n",
        "\n",
        "def pad_to_max_dimensions(image, max_height, max_width, fill_value=-9999):\n",
        "    \"\"\"\n",
        "    Pads an array (C, H, W) to match (C, max_height, max_width).\n",
        "    \"\"\"\n",
        "    bands, height, width = image.shape\n",
        "    padded_image = np.full((bands, max_height, max_width), fill_value, dtype=image.dtype)\n",
        "    padded_image[:, :height, :width] = image\n",
        "    return padded_image\n",
        "\n",
        "\n",
        "def generate_sequences_from_folders(folders, target_band_names, gdf, scaler=None, scaler_path=None):\n",
        "    \"\"\"\n",
        "    Generates sequences from folders containing rasters.\n",
        "    Each folder should contain 13 images (e.g., 13 months).\n",
        "    Also performs padding and standardization (StandardScaler).\n",
        "    Returns a 5D array: (tiles, timesteps=13, bands, height, width).\n",
        "    \"\"\"\n",
        "    max_height, max_width = 0, 0\n",
        "    all_images = []\n",
        "\n",
        "    # Determine max height and width\n",
        "    for folder in folders:\n",
        "        image_paths = [\n",
        "            os.path.join(folder, f)\n",
        "            for f in os.listdir(folder)\n",
        "            if f.endswith(('.tif', '.tiff'))\n",
        "        ]\n",
        "        for image_path in image_paths:\n",
        "            with rasterio.open(image_path) as src:\n",
        "                max_height = max(max_height, src.height)\n",
        "                max_width = max(max_width, src.width)\n",
        "\n",
        "    # Process images in each folder\n",
        "    for folder in folders:\n",
        "        image_paths = sorted([\n",
        "            os.path.join(folder, f)\n",
        "            for f in os.listdir(folder)\n",
        "            if f.endswith(('.tif', '.tiff'))\n",
        "        ])\n",
        "\n",
        "        # Group into blocks of 13 timesteps\n",
        "        num_tiles = len(image_paths) // 13\n",
        "        if len(image_paths) % 13 != 0:\n",
        "            raise ValueError(\"Number of images is not a multiple of 13.\")\n",
        "\n",
        "        for i in range(num_tiles):\n",
        "            tile_images = []\n",
        "            for j in range(13):\n",
        "                with rasterio.open(image_paths[i * 13 + j]) as src:\n",
        "                    band_names = list(src.descriptions)\n",
        "\n",
        "                    # Select bands\n",
        "                    selected_bands = select_band_by_name(src, band_names, target_band_names)\n",
        "                    if selected_bands is None:\n",
        "                        raise ValueError(f\"Bands {target_band_names} not found in {band_names}.\")\n",
        "\n",
        "                    # Apply mask (optionally, if you want to clip with polygons from gdf)\n",
        "                    out_image, _ = mask(\n",
        "                        src,\n",
        "                        gdf.geometry,\n",
        "                        crop=False,\n",
        "                        all_touched=True\n",
        "                    )\n",
        "\n",
        "                    # Filter only the target bands\n",
        "                    out_image = out_image[np.isin(band_names, target_band_names)]\n",
        "\n",
        "                    # Padding\n",
        "                    padded_image = pad_to_max_dimensions(out_image, max_height, max_width, fill_value=-9999)\n",
        "                    tile_images.append(padded_image)\n",
        "\n",
        "            # Stack (timesteps=13, bands, height, width)\n",
        "            tile_sequence = np.stack(tile_images, axis=0)\n",
        "            all_images.append(tile_sequence)\n",
        "\n",
        "    all_images = np.array(all_images)  # shape: (n_tiles, 13, bands, H, W)\n",
        "    n_tiles, timesteps, n_bands, height, width = all_images.shape\n",
        "\n",
        "    # Transpose and reshape for scaling\n",
        "    transposed_images = all_images.transpose(0, 1, 3, 4, 2)\n",
        "    reshaped_images = transposed_images.reshape(-1, n_bands)\n",
        "\n",
        "    # Standardization\n",
        "    if scaler is None:\n",
        "        scaler = StandardScaler()\n",
        "        is_training = True\n",
        "    else:\n",
        "        is_training = False\n",
        "\n",
        "    valid_mask = (reshaped_images != -9999).all(axis=1)\n",
        "    valid_data = reshaped_images[valid_mask]\n",
        "\n",
        "    standardized_data = reshaped_images.copy()\n",
        "    if is_training:\n",
        "        standardized_data[valid_mask] = scaler.fit_transform(valid_data)\n",
        "        if scaler_path:\n",
        "            joblib.dump(scaler, scaler_path)\n",
        "    else:\n",
        "        standardized_data[valid_mask] = scaler.transform(valid_data)\n",
        "\n",
        "    # Reshape back to original shape\n",
        "    standardized_images = (\n",
        "        standardized_data.reshape(n_tiles, timesteps, height, width, n_bands)\n",
        "        .transpose(0, 1, 4, 2, 3)\n",
        "    )\n",
        "\n",
        "    # Print stats\n",
        "    for band_idx in range(n_bands):\n",
        "        valid_band_data = standardized_images[..., band_idx, :, :][\n",
        "            standardized_images[..., band_idx, :, :] != -9999\n",
        "        ]\n",
        "        print(f\"\\nBand {band_idx} ({target_band_names[band_idx]}) stats:\")\n",
        "        print(f\"Mean: {np.mean(valid_band_data):.8f}\")\n",
        "        print(f\"Std:  {np.std(valid_band_data):.8f}\")\n",
        "\n",
        "    return standardized_images, scaler\n",
        "\n",
        "\n",
        "def create_sequence_labels(mask_path, sequence_shape):\n",
        "    \"\"\"\n",
        "    Create binary labels from a mask file.\n",
        "    Resulting shape: (n_sequences, timesteps, height, width)\n",
        "    \"\"\"\n",
        "    import rasterio\n",
        "    from skimage.transform import resize\n",
        "\n",
        "    # Read the mask\n",
        "    with rasterio.open(mask_path) as src:\n",
        "        mask = src.read(1)\n",
        "\n",
        "    # Binary (1=tree, 0=non-tree)\n",
        "    binary_mask = (mask > 0).astype(np.int32)\n",
        "\n",
        "    n_sequences, timesteps, _, height, width = sequence_shape\n",
        "\n",
        "    # Resize if dimensions don't match\n",
        "    if binary_mask.shape != (height, width):\n",
        "        print(f\"Resizing mask from {binary_mask.shape} to {(height, width)}\")\n",
        "        binary_mask = resize(binary_mask, (height, width), order=0, preserve_range=True).astype(np.int32)\n",
        "\n",
        "    # Repeat across timesteps\n",
        "    timestep_labels = np.repeat(binary_mask[np.newaxis, :, :], timesteps, axis=0)\n",
        "\n",
        "    # Repeat across sequences\n",
        "    labels = np.repeat(timestep_labels[np.newaxis, :, :, :], n_sequences, axis=0)\n",
        "\n",
        "    return labels\n",
        "\n",
        "\n",
        "def create_multi_sequence_labels(mask_paths, sequence_shape):\n",
        "    \"\"\"\n",
        "    Create binary labels for multiple mask files.\n",
        "    Example: if there are 10 training folders, pass 10 masks.\n",
        "    \"\"\"\n",
        "    import rasterio\n",
        "    from skimage.transform import resize\n",
        "\n",
        "    n_sequences, timesteps, _, target_height, target_width = sequence_shape\n",
        "    sequences_per_folder = n_sequences // len(mask_paths)\n",
        "\n",
        "    all_labels = []\n",
        "    for mask_path in mask_paths:\n",
        "        with rasterio.open(mask_path) as src:\n",
        "            mask = src.read(1)\n",
        "            binary_mask = (mask > 0).astype(np.int32)\n",
        "\n",
        "            # Adjust dimensions if needed\n",
        "            if binary_mask.shape != (target_height, target_width):\n",
        "                print(f\"Resizing mask from {binary_mask.shape} to {(target_height, target_width)}\")\n",
        "                binary_mask = resize(binary_mask, (target_height, target_width),\n",
        "                                     order=0, preserve_range=True).astype(np.int32)\n",
        "\n",
        "            folder_labels = np.repeat(binary_mask[np.newaxis, np.newaxis, :, :], sequences_per_folder, axis=0)\n",
        "            all_labels.append(folder_labels)\n",
        "\n",
        "    return np.concatenate(all_labels, axis=0)\n",
        "\n",
        "\n",
        "def calculate_statistics(true_labels, predicted_labels):\n",
        "    \"\"\"\n",
        "    Calculate classification metrics: confusion matrix, classification report, etc.\n",
        "    \"\"\"\n",
        "    true_labels = true_labels.flatten()\n",
        "    predicted_labels = predicted_labels.flatten()\n",
        "\n",
        "    cm = confusion_matrix(true_labels, predicted_labels, labels=[0, 1])\n",
        "    print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "    # Overall Accuracy\n",
        "    oa = np.trace(cm) / np.sum(cm)\n",
        "\n",
        "    # Producer's Accuracy\n",
        "    pa = cm.diagonal() / cm.sum(axis=1)\n",
        "\n",
        "    # User's Accuracy\n",
        "    pu = cm.diagonal() / cm.sum(axis=0)\n",
        "\n",
        "    report = classification_report(true_labels, predicted_labels, target_names=[\"Non-Tree\", \"Tree\"])\n",
        "    print(\"\\nClassification Report:\\n\", report)\n",
        "\n",
        "    return {\n",
        "        \"Overall Accuracy\": oa,\n",
        "        \"Producers Accuracy\": pa,\n",
        "        \"Users Accuracy\": pu\n",
        "    }\n",
        "\n",
        "\n",
        "def visualize_raster_predictions(raster_path, predictions, save_path=None):\n",
        "    \"\"\"\n",
        "    Visualize and (optionally) save predictions as GeoTIFF.\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    import rasterio\n",
        "\n",
        "    with rasterio.open(raster_path) as src:\n",
        "        profile = src.profile\n",
        "        profile.update(dtype=rasterio.uint8, count=1)\n",
        "        if save_path:\n",
        "            with rasterio.open(save_path, 'w', **profile) as dst:\n",
        "                dst.write(predictions.astype(rasterio.uint8), 1)\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.imshow(predictions, cmap='viridis', interpolation='none')\n",
        "    plt.colorbar(label=\"Predicted Labels\")\n",
        "    plt.title(\"Predicted Labels Raster\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "2VuhNlHhpDTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Label File Setup (Shapefiles or Polygons Generated from Points)"
      ],
      "metadata": {
        "id": "HEablnUkpGWv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### This section will load a polygon shapefile (e.g., generated from points), read a reference raster, and create a labeled mask (GeoTIFF) based on a specific attribute column (Species_id). Each polygon is assigned an integer label in the resulting mask, aligning with the reference raster's spatial properties."
      ],
      "metadata": {
        "id": "QzPlwTsiVonq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example path to shapefile (polygons)\n",
        "# This file should be the shapefile containing your polygons\n",
        "shapefile_path = 'example/file/path/Merged_polygons.shp'\n",
        "gdf = gpd.read_file(shapefile_path)\n",
        "\n",
        "# Load a reference raster\n",
        "# This file should be the reference raster you want to open\n",
        "reference_raster_path = 'example/file/path/Quercus_11_Monthly_2023-05.tif'\n",
        "reference_raster = rasterio.open(reference_raster_path)\n",
        "\n",
        "# Output mask path\n",
        "# This is where the output mask (label) will be saved\n",
        "output_mask_path = 'example/file/path/quercus_11_label.tif'\n",
        "\n",
        "# Create the mask\n",
        "create_labeled_mask(\n",
        "    gdf=gdf,\n",
        "    reference_raster=reference_raster,\n",
        "    output_path=output_mask_path,\n",
        "    id_column='Species_id'  # Shapefile column containing species ID\n",
        ")\n",
        "\n",
        "reference_raster.close()\n"
      ],
      "metadata": {
        "id": "1nKmKzhFpPuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating Sequences and Training/Test Tensors"
      ],
      "metadata": {
        "id": "c6LbO6PJpjC2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Here we generate input (images) and label (mask) tensors from multiple image folders. Each folder has 13 images (e.g., 13 months)."
      ],
      "metadata": {
        "id": "p_UvDkGtpkZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define folders\n",
        "# Each folder should contain your monthly mosaic files for different Quercus instances\n",
        "folders = [\n",
        "    'example/file/path/Quercus_1',\n",
        "    'example/file/path/Quercus_2',\n",
        "    'example/file/path/Quercus_4',\n",
        "    'example/file/path/Quercus_5',\n",
        "    'example/file/path/Quercus_6',\n",
        "    'example/file/path/Quercus_7',\n",
        "    'example/file/path/Quercus_8',\n",
        "    'example/file/path/Quercus_9',\n",
        "    'example/file/path/Quercus_10',\n",
        "    'example/file/path/Quercus_11'\n",
        "]\n",
        "test_folder = 'example/file/path/Quercus_3'\n",
        "\n",
        "# Re-load the shapefile for masking\n",
        "# This file should be the shapefile containing your polygons\n",
        "shapefile_path = 'example/file/path/Merged_polygons.shp'\n",
        "gdf = gpd.read_file(shapefile_path)\n",
        "\n",
        "# Target band names\n",
        "band_names = ['NDWI', 'VARI', 'NDVI', 'rededge']\n",
        "\n",
        "# Generate training sequences\n",
        "train_sequences, scaler_train = generate_sequences_from_folders(\n",
        "    folders,\n",
        "    target_band_names=band_names,\n",
        "    gdf=gdf\n",
        ")\n",
        "\n",
        "# Generate test sequences\n",
        "test_sequences, scaler_test = generate_sequences_from_folders(\n",
        "    [test_folder],\n",
        "    target_band_names=band_names,\n",
        "    gdf=gdf\n",
        ")\n",
        "\n",
        "# Create training masks (multi)\n",
        "# These paths should point to the label TIFF files corresponding to each Quercus folder above\n",
        "train_labels = create_multi_sequence_labels(\n",
        "    [\n",
        "        'example/file/path/quercus_1_label.tif',\n",
        "        'example/file/path/quercus_2_label.tif',\n",
        "        'example/file/path/quercus_4_label.tif',\n",
        "        'example/file/path/quercus_5_label.tif',\n",
        "        'example/file/path/quercus_6_label.tif',\n",
        "        'example/file/path/quercus_7_label.tif',\n",
        "        'example/file/path/quercus_8_label.tif',\n",
        "        'example/file/path/quercus_9_label.tif',\n",
        "        'example/file/path/quercus_10_label.tif',\n",
        "        'example/file/path/quercus_11_label.tif'\n",
        "    ],\n",
        "    train_sequences.shape\n",
        ")\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "train_tensor = torch.from_numpy(train_sequences).float()\n",
        "train_labels_tensor = torch.from_numpy(train_labels).long()\n",
        "\n",
        "# Generate test labels (if needed, single mask example):\n",
        "# This path should be the label TIFF file for the test folder (Quercus_3)\n",
        "test_mask_path = 'example/file/path/quercus_3_label.tif'\n",
        "test_labels = create_sequence_labels(test_mask_path, test_sequences.shape)\n",
        "test_tensor = torch.from_numpy(test_sequences).float()\n",
        "test_labels_tensor = torch.from_numpy(test_labels).long()\n",
        "\n",
        "# Check shapes\n",
        "print(f\"Train Tensor Shape: {train_tensor.shape}, dtype: {train_tensor.dtype}\")\n",
        "print(f\"Train Labels Tensor Shape: {train_labels_tensor.shape}, dtype: {train_labels_tensor.dtype}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "8hRx58C0pZ4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### If you wish to save these tensors for future use:"
      ],
      "metadata": {
        "id": "DS1g-zDOpvIg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save tensors to disk\n",
        "# This file will store the training and testing tensors along with their labels\n",
        "torch.save({\n",
        "    'train_data': train_tensor,\n",
        "    'train_labels': train_labels_tensor,\n",
        "    'test_data': test_tensor,\n",
        "    'test_labels': test_labels_tensor\n",
        "}, 'example/file/path/q1_11train_q3test_4_bands_tensors.pt')\n",
        "\n",
        "# Load saved tensors\n",
        "# This path should point to the saved tensors file\n",
        "loaded_tensors = torch.load('example/file/path/q1_11train_q3test_4_bands_tensors.pt')\n",
        "train_tensor = loaded_tensors['train_data']\n",
        "train_labels_tensor = loaded_tensors['train_labels']\n",
        "test_tensor = loaded_tensors['test_data']\n",
        "test_labels_tensor = loaded_tensors['test_labels']\n"
      ],
      "metadata": {
        "id": "UXavR7ropw9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining and Training the Model"
      ],
      "metadata": {
        "id": "dAYxxsqkp9eG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Now you will define a spatio-temporal CNN model for tree crown (cork oak) classification and a corresponding training pipeline.**\n",
        "\n",
        "The ModelConfig dataclass specifies default hyperparameters (e.g., number of bands, channel sizes, dropout rate). The SpatioTemporalModel processes time-series inputs through convolutional layers, producing both a pixel-wise crown prediction and a rough estimate of tree count. The CorkOakTrainer orchestrates the training loop, computing the cross-entropy loss for pixel classification, overall accuracy, and tree count estimates."
      ],
      "metadata": {
        "id": "DZKlnlr3YP7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class ModelConfig:\n",
        "    \"\"\"\n",
        "    Configuration for the SpatioTemporalModel.\n",
        "    \"\"\"\n",
        "    n_bands: int = 17\n",
        "    cnn_channels: list = None\n",
        "    cnn_kernel_size: int = 3\n",
        "    cnn_dropout: float = 0.1\n",
        "    learning_rate: float = 0.001\n",
        "    avg_tree_pixels: int = 10  # Used for tree count estimation\n",
        "\n",
        "    def __post_init__(self):\n",
        "        if self.cnn_channels is None:\n",
        "            self.cnn_channels = [32, 64, 128]\n",
        "\n",
        "\n",
        "class SpatioTemporalModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Spatio-temporal CNN model, including tree count estimation.\n",
        "    \"\"\"\n",
        "    def __init__(self, config: ModelConfig):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        # CNN layers\n",
        "        cnn_layers = []\n",
        "        in_channels = config.n_bands\n",
        "        for out_channels in config.cnn_channels:\n",
        "            cnn_layers.extend([\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=config.cnn_kernel_size, padding=config.cnn_kernel_size//2),\n",
        "                nn.BatchNorm2d(out_channels),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout2d(config.cnn_dropout)\n",
        "            ])\n",
        "            in_channels = out_channels\n",
        "        self.cnn = nn.Sequential(*cnn_layers)\n",
        "\n",
        "        # Pixel classifier\n",
        "        self.pixel_classifier = nn.Conv2d(\n",
        "            in_channels=config.cnn_channels[-1],\n",
        "            out_channels=2,\n",
        "            kernel_size=1\n",
        "        )\n",
        "\n",
        "    def estimate_tree_count(self, crown_predictions):\n",
        "        \"\"\"\n",
        "        Estimate the number of trees based on canopy cover pixels.\n",
        "        \"\"\"\n",
        "        crown_pixels = torch.sum(crown_predictions, dim=(1,2))\n",
        "        tree_count = crown_pixels / self.config.avg_tree_pixels\n",
        "        return tree_count\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: (batch_size, timesteps, bands, height, width)\n",
        "        Returns (crown_pred, tree_count).\n",
        "        \"\"\"\n",
        "        batch_size, timesteps, bands, height, width = x.shape\n",
        "        cnn_features = []\n",
        "\n",
        "        for t in range(timesteps):\n",
        "            features = self.cnn(x[:, t])\n",
        "            cnn_features.append(features)\n",
        "\n",
        "        # Average over timesteps\n",
        "        cnn_features = torch.stack(cnn_features, dim=1).mean(dim=1)\n",
        "        crown_pred = self.pixel_classifier(cnn_features)\n",
        "\n",
        "        # Binary prediction\n",
        "        binary_pred = crown_pred.argmax(dim=1)\n",
        "        tree_count = self.estimate_tree_count(binary_pred)\n",
        "        return crown_pred, tree_count\n",
        "\n",
        "\n",
        "class CorkOakTrainer:\n",
        "    \"\"\"\n",
        "    Trainer for the SpatioTemporalModel.\n",
        "    \"\"\"\n",
        "    def __init__(self, config: ModelConfig, device=None):\n",
        "        self.config = config\n",
        "        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.model = SpatioTemporalModel(config).to(self.device)\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=config.learning_rate)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    def train_epoch(self, train_loader):\n",
        "        \"\"\"\n",
        "        Trains the model for 1 epoch.\n",
        "        \"\"\"\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        for data, target in train_loader:\n",
        "            data = data.to(self.device)\n",
        "            # target is (n, 1, h, w) -> remove extra dimension: target.squeeze(1)\n",
        "            target = target.squeeze(1).to(self.device)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            crown_pred, _ = self.model(data)\n",
        "            loss = self.criterion(crown_pred, target)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        return total_loss / len(train_loader)\n",
        "\n",
        "    def evaluate(self, val_loader):\n",
        "        \"\"\"\n",
        "        Evaluates the model on val_loader.\n",
        "        \"\"\"\n",
        "        self.model.eval()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        tree_counts = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data, target in val_loader:\n",
        "                data = data.to(self.device)\n",
        "                target = target.squeeze(1).to(self.device)\n",
        "\n",
        "                crown_pred, tree_count = self.model(data)\n",
        "                loss = self.criterion(crown_pred, target)\n",
        "                total_loss += loss.item()\n",
        "\n",
        "                pred = crown_pred.argmax(dim=1)\n",
        "                correct += pred.eq(target).sum().item()\n",
        "                total += target.numel()\n",
        "\n",
        "                tree_counts.extend(tree_count.cpu().numpy())\n",
        "\n",
        "        return (\n",
        "            total_loss / len(val_loader),\n",
        "            correct / total,\n",
        "            tree_counts\n",
        "        )\n"
      ],
      "metadata": {
        "id": "-gMuppkaqAd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####**Training Example**"
      ],
      "metadata": {
        "id": "Ka1gdFKuqHEp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **How to set up a training loop for the cork oak model.**\n",
        "\n",
        "First, it creates a PyTorch TensorDataset and DataLoader from the training tensors, specifying a batch_size and shuffling. Next, it initializes the model configuration (ModelConfig) using the number of input bands from the training data. The CorkOakTrainer is then used to train the model for a specified number of epochs, printing the training loss each time. Finally, the trained model’s parameters are saved to a .pth file."
      ],
      "metadata": {
        "id": "aTsutmtKY0X6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Dataset and DataLoader\n",
        "train_dataset = TensorDataset(train_tensor, train_labels_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "config = ModelConfig(n_bands=train_tensor.shape[2])\n",
        "trainer = CorkOakTrainer(config)\n",
        "\n",
        "num_epochs = 2  # example\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = trainer.train_epoch(train_loader)\n",
        "    print(f\"Epoch {epoch+1}: Training Loss = {train_loss:.4f}\")\n",
        "\n",
        "print(\"Training complete.\")\n",
        "\n",
        "# Save model\n",
        "# This path should point to where you want to save the trained model\n",
        "model_save_path = 'example/file/path/q1_11train_q3test_model.pth'\n",
        "torch.save(trainer.model.state_dict(), model_save_path)\n",
        "print(f\"Model saved at: {model_save_path}\")\n"
      ],
      "metadata": {
        "id": "nOKjGbLbqJFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation and Visualization of Results"
      ],
      "metadata": {
        "id": "WoMgGeosqRRu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Load a trained spatio-temporal model and apply it to the test set, generating predicted labels and estimating the number of trees. It calculates various classification metrics (overall, producer’s, and user’s accuracy) and visualizes the predictions over a reference raster. Finally, it compares the model’s estimated tree count to the actual number of trees derived from the shapefile."
      ],
      "metadata": {
        "id": "WEzhZhF7Z61Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load trained model (if needed)\n",
        "config = ModelConfig(n_bands=train_tensor.shape[2])\n",
        "model = SpatioTemporalModel(config)\n",
        "# This path should point to the saved trained model\n",
        "model_save_path = 'example/file/path/q1_11train_q3test_model.pth'\n",
        "model.load_state_dict(torch.load(model_save_path))\n",
        "model.eval()\n",
        "\n",
        "# Inference on the test set (assuming a single batch or adapting DataLoader)\n",
        "with torch.no_grad():\n",
        "    crown_pred, tree_count = model(test_tensor)\n",
        "\n",
        "# Predictions\n",
        "test_predictions = crown_pred.argmax(dim=1).cpu().numpy()\n",
        "\n",
        "# True labels, if you want stats\n",
        "true_labels_test = test_labels_tensor.squeeze(1).cpu().numpy()\n",
        "\n",
        "# Statistics\n",
        "stats = calculate_statistics(true_labels_test, test_predictions)\n",
        "print(\"\\nMetrics:\")\n",
        "print(f\"OA (Overall Accuracy): {stats['Overall Accuracy']:.2f}\")\n",
        "print(f\"PA (Producer's Accuracy): {stats['Producers Accuracy']}\")\n",
        "print(f\"UA (User's Accuracy): {stats['Users Accuracy']}\")\n",
        "\n",
        "# Visualization (example for the first tile/time)\n",
        "# This path should point to the raster file you want to visualize\n",
        "quercus_3_raster_path = 'example/file/path/Quercus_3_Monthly_2023-05.tif'\n",
        "# This path should point to where you want to save the prediction visualization\n",
        "visualize_raster_predictions(\n",
        "    raster_path=quercus_3_raster_path,\n",
        "    predictions=test_predictions[0],\n",
        "    save_path='example/file/path/example_prediction.tif'\n",
        ")\n",
        "\n",
        "# Tree count comparison\n",
        "# This path should point to the shapefile containing your polygons\n",
        "shapefile_path = 'example/file/path/Merged_polygons.shp'\n",
        "gdf = gpd.read_file(shapefile_path)\n",
        "with rasterio.open(quercus_3_raster_path) as src:\n",
        "    bounds = src.bounds\n",
        "    raster_bbox = box(*bounds)\n",
        "    gdf_filtered = gdf[gdf.geometry.intersects(raster_bbox)]\n",
        "    actual_tree_count = len(gdf_filtered)\n",
        "\n",
        "print(\"\\nTree Count Comparison:\")\n",
        "print(f\"Actual trees in shapefile: {actual_tree_count}\")\n",
        "print(f\"Estimated trees by the model (first tile): {int(tree_count[0].item())}\")\n"
      ],
      "metadata": {
        "id": "UEcRlJ35qTA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validation in a Test Area / Inference"
      ],
      "metadata": {
        "id": "22VMMEWvqcdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **How to validate the model on a different test area (folder).**\n",
        "\n",
        "First, it identifies the indices of relevant bands in a reference raster (e.g., NDVI, NDWI, VARI). It then generates standardized sequences by reading and padding the images in the folder to consistent dimensions. Using a previously trained scaler, it standardizes the data and converts it to a PyTorch tensor for inference. The model’s predictions are then analyzed to compute basic statistics on the proportion of tree pixels."
      ],
      "metadata": {
        "id": "0ECCvEn3aYUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def identify_band_indices(file_path, target_band_names):\n",
        "    \"\"\"\n",
        "    Identify indices of the required bands in a raster.\n",
        "    \"\"\"\n",
        "    with rasterio.open(file_path) as src:\n",
        "        band_names = list(src.descriptions)\n",
        "        band_indices = [\n",
        "            band_names.index(band) + 1 if band in band_names else None\n",
        "            for band in target_band_names\n",
        "        ]\n",
        "        for band, index in zip(target_band_names, band_indices):\n",
        "            if index is None:\n",
        "                raise ValueError(f\"Band {band} not found.\")\n",
        "    return band_indices\n",
        "\n",
        "\n",
        "def generate_sequences_with_band_indices(folders, band_indices, scaler=None):\n",
        "    \"\"\"\n",
        "    Generate sequences (13 timesteps) using already identified band indices.\n",
        "    Apply a given scaler if provided.\n",
        "    \"\"\"\n",
        "    sequences = []\n",
        "    max_height, max_width = 0, 0\n",
        "\n",
        "    # Determine max dimensions\n",
        "    for folder in folders:\n",
        "        image_paths = [\n",
        "            os.path.join(folder, f)\n",
        "            for f in os.listdir(folder)\n",
        "            if f.endswith(('.tif', '.tiff'))\n",
        "        ]\n",
        "        for image_path in image_paths:\n",
        "            with rasterio.open(image_path) as src:\n",
        "                max_height = max(max_height, src.height)\n",
        "                max_width = max(max_width, src.width)\n",
        "\n",
        "    # Read and stack images\n",
        "    for folder in folders:\n",
        "        image_paths = sorted([\n",
        "            os.path.join(folder, f)\n",
        "            for f in os.listdir(folder)\n",
        "            if f.endswith(('.tif', '.tiff'))\n",
        "        ])\n",
        "\n",
        "        num_tiles = len(image_paths) // 13\n",
        "        if len(image_paths) % 13 != 0:\n",
        "            raise ValueError(\"Number of images is not a multiple of 13.\")\n",
        "\n",
        "        for i in range(num_tiles):\n",
        "            tile_images = []\n",
        "            for j in range(13):\n",
        "                with rasterio.open(image_paths[i * 13 + j]) as src:\n",
        "                    selected_bands = src.read(band_indices)\n",
        "                    padded_image = np.full(\n",
        "                        (selected_bands.shape[0], max_height, max_width),\n",
        "                        -9999,\n",
        "                        dtype=selected_bands.dtype\n",
        "                    )\n",
        "                    padded_image[:, :selected_bands.shape[1], :selected_bands.shape[2]] = selected_bands\n",
        "                    tile_images.append(padded_image)\n",
        "            sequences.append(np.stack(tile_images, axis=0))\n",
        "\n",
        "    sequences = np.array(sequences)  # shape: (tiles, timesteps, bands, H, W)\n",
        "    n_tiles, timesteps, n_bands, height, width = sequences.shape\n",
        "\n",
        "    # Standardization\n",
        "    transposed_sequences = sequences.transpose(0, 1, 3, 4, 2)\n",
        "    reshaped_sequences = transposed_sequences.reshape(-1, n_bands)\n",
        "\n",
        "    if scaler is None:\n",
        "        scaler = StandardScaler()\n",
        "        is_training = True\n",
        "    else:\n",
        "        is_training = False\n",
        "\n",
        "    valid_mask = (reshaped_sequences != -9999).all(axis=1)\n",
        "    valid_data = reshaped_sequences[valid_mask]\n",
        "\n",
        "    standardized_data = reshaped_sequences.copy()\n",
        "    if is_training:\n",
        "        standardized_data[valid_mask] = scaler.fit_transform(valid_data)\n",
        "    else:\n",
        "        standardized_data[valid_mask] = scaler.transform(valid_data)\n",
        "\n",
        "    standardized_sequences = (\n",
        "        standardized_data.reshape(n_tiles, timesteps, height, width, n_bands)\n",
        "        .transpose(0, 1, 4, 2, 3)\n",
        "    )\n",
        "\n",
        "    return standardized_sequences\n",
        "\n",
        "\n",
        "# Example usage in validation\n",
        "# This path should point to the validation folder containing the raster files\n",
        "validation_folder = \"example/file/path/Validacion_holm_oak\"\n",
        "# This path should point to the reference raster within the validation folder\n",
        "reference_raster_path = os.path.join(validation_folder, \"Validacion_holm_oak_Monthly_2023-05.tif\")\n",
        "band_names = ['NDWI', 'VARI', 'NDVI', 'rededge']\n",
        "\n",
        "band_indices = identify_band_indices(reference_raster_path, band_names)\n",
        "validation_sequences = generate_sequences_with_band_indices([validation_folder], band_indices, scaler=scaler_train)\n",
        "\n",
        "# We take only 1 timestep if we want to test a single month...\n",
        "validation_tensor = torch.tensor(validation_sequences[:, 0, :, :, :], dtype=torch.float32)\n",
        "\n",
        "# Inference\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    crown_pred_val, tree_count_val = model(validation_tensor.to('cpu'))  # Adjust if device is 'cuda'\n",
        "    test_predictions_val = crown_pred_val.argmax(dim=1).cpu().numpy()\n",
        "\n",
        "# Basic stats\n",
        "def calculate_tree_stats_from_predictions(predictions, nodata_value=-9999):\n",
        "    valid_mask = predictions != nodata_value\n",
        "    tree_pixels = np.sum(predictions[valid_mask] == 1)\n",
        "    total_pixels = np.sum(valid_mask)\n",
        "    tree_fraction = tree_pixels / total_pixels if total_pixels > 0 else 0\n",
        "    return {\n",
        "        'tree_pixels': tree_pixels,\n",
        "        'total_pixels': total_pixels,\n",
        "        'tree_fraction': tree_fraction,\n",
        "    }\n",
        "\n",
        "stats_val = calculate_tree_stats_from_predictions(test_predictions_val[0])\n",
        "print(\"Validation image statistics:\", stats_val)\n"
      ],
      "metadata": {
        "id": "0s73p8xVqd6m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}