{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "-8zmFKAg-cF0",
        "aj46kJnZm6tj"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Notebook for running the model"
      ],
      "metadata": {
        "id": "UiCj4WV95wM5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 - Access to Data\n"
      ],
      "metadata": {
        "id": "-8zmFKAg-cF0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For access to the satellite data of **PlanetScope**, we use an academic access that is free but limited. Students or researchers can apply for access by following [this link](https://www.planet.com/industries/education-and-research/). It is important to review the access limitations specific to the user account.\n",
        "\n",
        "A complete guide to download the satellite images using **QGIS** is available [here](https://github.com/domwelsh/quercus-detection/blob/main/documentation/satellite_images_download/satellite_images_download_doc.md).\n"
      ],
      "metadata": {
        "id": "Rf_PTGdgv0u9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2- Data Preparation"
      ],
      "metadata": {
        "id": "B3oZVlCcGdZ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preparation Requirements\n",
        "\n",
        "To prepare the data for processing, follow these steps after downloading the satellite images:\n",
        "\n",
        "1. **Upload Satellite Images to a Google Cloud Bucket**  \n",
        "   - You can find a detailed description of the upload process in [this guide](https://github.com/domwelsh/quercus-detection/blob/main/documentation/indexes_calculation/indexes_calculation_doc.md).  \n",
        "   - Alternatively, you can upload your images manually by following the instructions in [this video tutorial](https://www.youtube.com/watch?v=4MnQnYMTEU0&ab_channel=Codible).\n",
        "\n",
        "2. **Transfer Images from Google Cloud to a GEE Asset**  \n",
        "   - Use a notebook to facilitate this process (you also can see a example here: [example](https://github.com/domwelsh/quercus-detection/blob/main/notebooks/Index_calculation_planet_scope/1.Upload_images_from_GC_to_GEE.ipynb). Ensure your images are properly organized within Google Cloud before transferring them.\n",
        "\n",
        "3. **Execute a Notebook for GEE Integration**  \n",
        "   - This will enable you to transfer the images to Google Drive and run the notebook using Google Colab.\n",
        "\n",
        "By following these steps, your satellite images will be ready for further analysis and processing.\n"
      ],
      "metadata": {
        "id": "-FXEc-cHxWnU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Code to Transfer Images from Google Cloud to a GEE Asset"
      ],
      "metadata": {
        "id": "eDWc5rkIzBBE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOTE:\n",
        "\n",
        "For this you need to acces to your credential of Google Cloud, for obtain the files of service_account_path: [https://developers.google.com/workspace/guides/create-credentials?hl=es-419](Access here)"
      ],
      "metadata": {
        "id": "_R6mCxm10SAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install rasterio earthengine-api google-cloud-storage google-auth google-auth-oauthlib"
      ],
      "metadata": {
        "id": "mCRs8DqNzIX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.oauth2 import service_account\n",
        "from google.cloud import storage\n",
        "\n",
        "# Replace with the path to your service account key file\n",
        "service_account_path = 'C:/Users/your-user/ee-your-user-02041da0749c.json'\n",
        "\n",
        "# Set up the credentials\n",
        "credentials = service_account.Credentials.from_service_account_file(service_account_path)\n",
        "\n",
        "# Initialize the storage client\n",
        "storage_client = storage.Client(credentials=credentials)\n",
        "\n",
        "# List all buckets\n",
        "buckets = list(storage_client.list_buckets())\n",
        "for bucket in buckets:\n",
        "    print(bucket.name)\n",
        "\n",
        "\n",
        "# NOTE: for this you need to access to your credential of Google Cloud"
      ],
      "metadata": {
        "id": "iIAjRAVQzvDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ee\n",
        "ee.Authenticate()\n",
        "ee.Initialize()"
      ],
      "metadata": {
        "id": "b9u-oQ241URs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "from google.oauth2 import service_account\n",
        "from google.cloud import storage\n",
        "import ee\n",
        "from datetime import datetime\n",
        "\n",
        "# Configure credentials file and parameters\n",
        "service_account_path = 'C:/Users/user-name/ee-your-user-02041da0749c.json'\n",
        "BUCKET_NAME = 'name_of_your_bucket'\n",
        "BASE_PATH = 'Folder_with_your_images_of_planet'\n",
        "COLLECTION = 'projects/your_asset_in_GEE'\n",
        "BAND_NAMES = ['coastal_blue', 'blue', 'green_i', 'green', 'yellow', 'red', 'rededge', 'nir']\n",
        "EXCEL_OUTPUT = 'gee_output.xlsx'  # Output file with a list of the uploaded files\n",
        "\n",
        "def initialize_ee():\n",
        "    try:\n",
        "        ee.Initialize()\n",
        "        print(\"Google Earth Engine initialized.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing Earth Engine: {e}\")\n",
        "        raise\n",
        "\n",
        "def initialize_storage_client():\n",
        "    creds = service_account.Credentials.from_service_account_file(service_account_path)\n",
        "    return storage.Client(credentials=creds)\n",
        "\n",
        "def list_files(bucket_name, base_path):\n",
        "    print(\"Listing files in the bucket...\")\n",
        "    storage_client = initialize_storage_client()\n",
        "    blobs = storage_client.list_blobs(bucket_name, prefix=base_path)\n",
        "    # Only add files that match the exact pattern YYYY-MM-DD_strip_######_composite.tif\n",
        "    pattern = r'\\d{4}-\\d{2}-\\d{2}_strip_\\d+_composite\\.tif$'\n",
        "    files = [blob.name for blob in blobs if re.search(pattern, blob.name)]\n",
        "    print(\"Files listed:\", files)\n",
        "    return files\n",
        "\n",
        "def extract_date_from_filename(filename):\n",
        "    print(f\"Extracting date from file: {filename}\")\n",
        "    match = re.search(r'(\\d{4}-\\d{2}-\\d{2})', filename)  # Date in format YYYY-MM-DD\n",
        "    if match:\n",
        "        formatted_date = match.group(1)\n",
        "        print(f\"Date extracted: {formatted_date}\")\n",
        "        return formatted_date\n",
        "    else:\n",
        "        print(f\"No date found in filename: {filename}\")\n",
        "        return None\n",
        "\n",
        "def upload_file(uri_gcs, asset_name, formatted_date):\n",
        "    print(f\"Uploading file to GEE: {asset_name} with date {formatted_date}\")\n",
        "    asset_id = f\"{COLLECTION}/{asset_name}\"\n",
        "    bands = [{'id': name, 'tileset_band_index': i} for i, name in enumerate(BAND_NAMES)]\n",
        "    start_time = f\"{formatted_date}T00:00:00Z\"\n",
        "    end_time = f\"{formatted_date}T23:59:59Z\"\n",
        "\n",
        "    manifest = {\n",
        "        'name': asset_id,\n",
        "        'tilesets': [{\n",
        "            'sources': [{\n",
        "                'uris': [uri_gcs]\n",
        "            }]\n",
        "        }],\n",
        "        'bands': bands,\n",
        "        'startTime': start_time,\n",
        "        'endTime': end_time\n",
        "    }\n",
        "    try:\n",
        "        task_id = ee.data.newTaskId()[0]\n",
        "        ee.data.startIngestion(task_id, manifest)\n",
        "        print(f\"Uploaded: {asset_name}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error uploading {asset_name}: {e}\")\n",
        "        return False\n",
        "\n",
        "def main():\n",
        "    initialize_ee()\n",
        "    files = list_files(BUCKET_NAME, BASE_PATH)\n",
        "    print(\"Files found:\", files)\n",
        "\n",
        "    uploaded_files = []  # To store data for Excel log\n",
        "\n",
        "    for file in files:\n",
        "        try:\n",
        "            file_name = file.split('/')[-1]\n",
        "            print(\"Processing file:\", file_name)\n",
        "            formatted_date = extract_date_from_filename(file_name)\n",
        "            print(\"Extracted date:\", formatted_date)\n",
        "            if formatted_date:\n",
        "                uri_gcs = f\"gs://{BUCKET_NAME}/{file}\"\n",
        "                asset_name = file_name.split('.')[0]\n",
        "                success = upload_file(uri_gcs, asset_name, formatted_date)\n",
        "                # Add entry to the log if upload is successful\n",
        "                if success:\n",
        "                    uploaded_files.append({'File Name': file_name, 'Extracted Date': formatted_date})\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing file {file}: {e}\")\n",
        "\n",
        "    # Save the log to an Excel file\n",
        "    df = pd.DataFrame(uploaded_files)\n",
        "    df.to_excel(EXCEL_OUTPUT, index=False)\n",
        "    print(f\"Log saved to {EXCEL_OUTPUT}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "YzLjh3xs1e_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Execute a Notebook for GEE Integration: Obtain the vegetation indexes and put your satellite images available in Google Drive\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "n_apO5GP4j6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a map to display the image and index\n",
        "Map = geemap.Map(center = (39.22, -8.97), zoom = 6) # You can change your coordinates to your study area\n",
        "Map\n",
        "\n",
        "# And Please Draw a point for your area of study in the displayed map"
      ],
      "metadata": {
        "id": "jJe3lYgH5LJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Map.user_roi.getInfo()\n",
        "#Define the geometry of the study area\n",
        "geometry = Map.user_roi # Please copy the result in to the next cell"
      ],
      "metadata": {
        "id": "-TGvv6xP5QAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the here the values of the last result\n",
        "geometry = ee.Geometry.Point([-8.607292, 38.134876]) # This is a example"
      ],
      "metadata": {
        "id": "LKTEEyum54fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the image collection\n",
        "collection = ee.ImageCollection(\"projects/your-user/assets/location_of_the_images_in_the_asset_of_gee\")\n",
        "\n",
        "# Filter by date (in this case is the same month of soil sampling)\n",
        "collection = collection.filterDate('YYYY-MM-DD', 'YYYY-MM-DD').filterBounds(geometry)\n",
        "\n",
        "# This function maps spectral indices using PlanetScope Imagery\n",
        "def addIndices(img):\n",
        "    # NDVI\n",
        "    NDVI = img.normalizedDifference(['nir', 'red']).rename('NDVI')\n",
        "\n",
        "    # NDWI (Normalized Difference Water Index)\n",
        "    NDWI = img.expression('(GREEN - NIR) / (GREEN + NIR)', {'NIR': img.select('nir'), 'GREEN': img.select('green')}).rename('NDWI')\n",
        "\n",
        "    # VARI (Visible Atmospherically Resistant Index)\n",
        "    VARI = img.expression('(Green - Red) / (Green + Red - Blue)', {'Blue': img.select('blue'), 'Red': img.select('red'), 'Green': img.select('green')}).rename('VARI')\n",
        "\n",
        "\n",
        "    return img.addBands([NDVI, NDWI, VARI])\n",
        "\n",
        "# Example usage\n",
        "ps = collection\n",
        "#Add the indices\n",
        "ps = ps.map(addIndices)\n",
        "composite = ps \\\n",
        "              .mean()\n",
        "\n",
        "Map.addLayer(composite, {'bands': ['red',  'green',  'blue'], 'min': 201, 'max': 2464}, 'RGB')"
      ],
      "metadata": {
        "id": "gQ921EMX53KV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 Export the montly mosaics to Google Drive"
      ],
      "metadata": {
        "id": "iKTCVoGb7K7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the date range for the collection\n",
        "start_date = ee.Date('YYYY-MM-DD')\n",
        "end_date = ee.Date('YYYY-MM-DD')\n",
        "\n",
        "\n",
        "collection_with_indices = collection.map(add_indices)\n",
        "\n",
        "# Function to create a monthly mosaic\n",
        "def average_by_month(start):\n",
        "    start = ee.Date(start)\n",
        "    end = start.advance(1, 'month')\n",
        "    monthly_images = collection_with_indices.filterDate(start, end)\n",
        "    mosaic = monthly_images.mean()\n",
        "    return mosaic.set('system:time_start', start.millis())\n",
        "\n",
        "# Create monthly mosaics\n",
        "monthly_mosaics = ee.ImageCollection.fromImages(\n",
        "    months.map(lambda m: ee.Image(average_by_month(m)))\n",
        ")\n",
        "\n",
        "# Export each mosaic to Google Drive\n",
        "for i in range(monthly_mosaics.size().getInfo()):\n",
        "    img = ee.Image(monthly_mosaics.toList(monthly_mosaics.size()).get(i))\n",
        "    date_str = ee.Date(img.get('system:time_start')).format('YYYY-MM').getInfo()\n",
        "    file_name = f\"Add_a_name_{date_str}.tif\" # Please add a name for the file this will be like 'Add_a_name_Monthly_YYYY-MM\"\n",
        "\n",
        "    # Export all bands as a single image\n",
        "    task = ee.batch.Export.image.toDrive(\n",
        "        image=img.toFloat(),\n",
        "        description=f\"Export_Add_a_name_{date_str}\",\n",
        "        folder='GEE_Exports',\n",
        "        fileNamePrefix=f\"{file_name}\",\n",
        "        scale=3,\n",
        "        crs=\"EPSG:3763\",\n",
        "        maxPixels=1e13\n",
        "    )\n",
        "    task.start()\n",
        "    print(f\"Exporting {file_name} to Google Drive\")"
      ],
      "metadata": {
        "id": "m5EFDbBf7B1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3- Model"
      ],
      "metadata": {
        "id": "et7g_oblt3II"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.1  Define the Needed Functions\n"
      ],
      "metadata": {
        "id": "BVZvhfOzG7qY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### This section defines essential functions for preprocessing raster data before model training. It includes:\n",
        "\n",
        "1. **identify_band_indices**: Finds the indices of specified spectral bands in a raster file.\n",
        "2. **generate_sequences_with_band_indices**: Creates sequences of images by selecting and padding the identified bands.\n",
        "3. **replace_nan_in_images**: Replaces NaN values in images with -9999 to ensure data consistency.\n",
        "4. **verify_band_statistics**: Checks the minimum, maximum, and mean values of each band to validate data quality."
      ],
      "metadata": {
        "id": "q6KroMCqKE24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the needed functions\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import rasterio\n",
        "\n",
        "# Step 1: Identify the indices of the necessary bands\n",
        "def identify_band_indices(file_path, target_band_names):\n",
        "    with rasterio.open(file_path) as src:\n",
        "        band_names = list(src.descriptions)\n",
        "        band_indices = [\n",
        "            band_names.index(band) + 1 if band in band_names else None\n",
        "            for band in target_band_names\n",
        "        ]\n",
        "        for band, index in zip(target_band_names, band_indices):\n",
        "            if index is None:\n",
        "                raise ValueError(f\"The band {band} was not found in the file.\")\n",
        "            print(f\"Band {band}: Index {index}\")\n",
        "    return band_indices\n",
        "\n",
        "# Step 2: Generate sequences using band indices\n",
        "def generate_sequences_with_band_indices(folders, band_indices):\n",
        "    sequences = []\n",
        "    max_height, max_width = 0, 0\n",
        "\n",
        "    # Calculate the maximum dimensions\n",
        "    for folder in folders:\n",
        "        image_paths = [\n",
        "            os.path.join(folder, f)\n",
        "            for f in os.listdir(folder)\n",
        "            if f.endswith(('.tif', '.tiff'))\n",
        "        ]\n",
        "        for image_path in image_paths:\n",
        "            with rasterio.open(image_path) as src:\n",
        "                max_height = max(max_height, src.height)\n",
        "                max_width = max(max_width, src.width)\n",
        "\n",
        "    # Process and group images into sequences\n",
        "    for folder in folders:\n",
        "        image_paths = sorted([\n",
        "            os.path.join(folder, f)\n",
        "            for f in os.listdir(folder)\n",
        "            if f.endswith(('.tif', '.tiff'))\n",
        "        ])\n",
        "\n",
        "        num_tiles = len(image_paths) // 13\n",
        "        if len(image_paths) % 13 != 0:\n",
        "            raise ValueError(\"The number of images is not a multiple of 13.\")\n",
        "\n",
        "        for i in range(num_tiles):\n",
        "            tile_images = []\n",
        "            for j in range(13):\n",
        "                with rasterio.open(image_paths[i * 13 + j]) as src:\n",
        "                    # Read the bands selected by index\n",
        "                    selected_bands = src.read(band_indices)\n",
        "                    padded_image = np.full(\n",
        "                        (selected_bands.shape[0], max_height, max_width),\n",
        "                        -9999, dtype=selected_bands.dtype\n",
        "                    )\n",
        "                    padded_image[:, :selected_bands.shape[1], :selected_bands.shape[2]] = selected_bands\n",
        "                    tile_images.append(padded_image)\n",
        "\n",
        "            sequences.append(np.stack(tile_images, axis=0))\n",
        "\n",
        "    return np.array(sequences)\n",
        "\n",
        "# Step 3: Replace NaN with -9999 in the images.\n",
        "def replace_nan_in_images(folder):\n",
        "    processed_folder = os.path.join(folder, \"processed\")\n",
        "    os.makedirs(processed_folder, exist_ok=True)\n",
        "\n",
        "    for file in sorted(os.listdir(folder)):\n",
        "        if file.endswith(('.tif', '.tiff')):\n",
        "            input_path = os.path.join(folder, file)\n",
        "            output_path = os.path.join(processed_folder, file)\n",
        "\n",
        "            with rasterio.open(input_path) as src:\n",
        "                profile = src.profile\n",
        "                data = src.read()\n",
        "                # Replace NaN with -9999\n",
        "                data = np.nan_to_num(data, nan=-9999)\n",
        "                # Save the processed image\n",
        "                with rasterio.open(output_path, 'w', **profile) as dst:\n",
        "                    dst.write(data)\n",
        "                print(f\"Processed {file} and saved to {output_path}\")\n",
        "    return processed_folder\n",
        "\n",
        "# Step 4: Verify the statistics of the bands\n",
        "def verify_band_statistics(folder, band_indices):\n",
        "    for file in sorted(os.listdir(folder)):\n",
        "        if file.endswith(('.tif', '.tiff')):\n",
        "            file_path = os.path.join(folder, file)\n",
        "            with rasterio.open(file_path) as src:\n",
        "                for idx in band_indices:\n",
        "                    band_data = src.read(idx)\n",
        "                    print(f\"Band {idx} - Min: {np.min(band_data)}, Max: {np.max(band_data)}, Mean: {np.mean(band_data)}\")"
      ],
      "metadata": {
        "id": "M7qsJPWm8fvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Define the model"
      ],
      "metadata": {
        "id": "SYXkdGzCHZof"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####**This section defines the spatio-temporal CNN model and its training pipeline.**\n",
        "\n",
        "The ModelConfig dataclass sets the model's hyperparameters. The SpatioTemporalModel class builds the CNN architecture for processing raster sequences. The CorkOakTrainer class manages the training and evaluation processes, including loss computation and accuracy measurement."
      ],
      "metadata": {
        "id": "rREtVGaSHi75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the model\n",
        "from dataclasses import dataclass\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "# Model Configuration and Definition\n",
        "@dataclass\n",
        "class ModelConfig:\n",
        "    \"\"\"\n",
        "    Configuration class for the SpatioTemporalModel.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    n_bands : int\n",
        "        Number of input spectral bands.\n",
        "    cnn_channels : list of int, optional\n",
        "        List of output channels for the CNN layers. Default is [32, 64, 128].\n",
        "    cnn_kernel_size : int, optional\n",
        "        Kernel size for the CNN convolutions. Default is 3.\n",
        "    cnn_dropout : float, optional\n",
        "        Dropout rate for the CNN layers. Default is 0.3.\n",
        "    learning_rate : float, optional\n",
        "        Learning rate for the optimizer. Default is 0.001.\n",
        "    \"\"\"\n",
        "    n_bands: int = 17\n",
        "    cnn_channels: list = None\n",
        "    cnn_kernel_size: int = 3\n",
        "    cnn_dropout: float = 0.1\n",
        "    learning_rate: float = 0.001\n",
        "\n",
        "    def __post_init__(self):\n",
        "        \"\"\"\n",
        "        Initializes default values for cnn_channels if not provided.\n",
        "        \"\"\"\n",
        "        if self.cnn_channels is None:\n",
        "            self.cnn_channels = [32, 64, 128]\n",
        "\n",
        "\n",
        "class SpatioTemporalModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Spatio-temporal CNN model for processing raster sequences.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    config : ModelConfig\n",
        "        Configuration object containing model hyperparameters.\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    forward(x)\n",
        "        Perform a forward pass of the model.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: ModelConfig):\n",
        "        \"\"\"\n",
        "        Initializes the CNN layers and pixel classifier based on the configuration.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        config : ModelConfig\n",
        "            Configuration object containing model hyperparameters.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        # Build CNN layers dynamically\n",
        "        cnn_layers = []\n",
        "        in_channels = config.n_bands\n",
        "        for out_channels in config.cnn_channels:\n",
        "            cnn_layers.extend([\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=config.cnn_kernel_size, padding=config.cnn_kernel_size // 2),\n",
        "                nn.BatchNorm2d(out_channels),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout2d(config.cnn_dropout)\n",
        "            ])\n",
        "            in_channels = out_channels\n",
        "        self.cnn = nn.Sequential(*cnn_layers)\n",
        "\n",
        "        # Pixel classifier layer\n",
        "        self.pixel_classifier = nn.Conv2d(in_channels=config.cnn_channels[-1], out_channels=2, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the model.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : torch.Tensor\n",
        "            Input tensor with shape (batch_size, timesteps, bands, height, width).\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        torch.Tensor\n",
        "            Output tensor with shape (batch_size, 2, height, width), where 2 is the number of classes.\n",
        "        \"\"\"\n",
        "        batch_size, timesteps, bands, height, width = x.shape\n",
        "        cnn_features = []\n",
        "        for t in range(timesteps):\n",
        "            features = self.cnn(x[:, t])\n",
        "            cnn_features.append(features)\n",
        "        cnn_features = torch.stack(cnn_features, dim=1).mean(dim=1)\n",
        "        return self.pixel_classifier(cnn_features)\n",
        "\n",
        "\n",
        "class CorkOakTrainer:\n",
        "    \"\"\"\n",
        "    Training and evaluation class for the SpatioTemporalModel.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    config : ModelConfig\n",
        "        Configuration object containing model hyperparameters.\n",
        "    device : str, optional\n",
        "        Device to run the model on ('cuda' or 'cpu'). Defaults to 'cuda' if available, otherwise 'cpu'.\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    train_epoch(train_loader)\n",
        "        Train the model for one epoch.\n",
        "    evaluate(val_loader)\n",
        "        Evaluate the model on a validation dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: ModelConfig, device=None):\n",
        "        \"\"\"\n",
        "        Initializes the trainer with the model, optimizer, and loss function.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        config : ModelConfig\n",
        "            Configuration object containing model hyperparameters.\n",
        "        device : str, optional\n",
        "            Device to run the model on ('cuda' or 'cpu'). Defaults to 'cuda' if available, otherwise 'cpu'.\n",
        "        \"\"\"\n",
        "        self.config = config\n",
        "        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.model = SpatioTemporalModel(config).to(self.device)\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=config.learning_rate)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    def train_epoch(self, train_loader):\n",
        "        \"\"\"\n",
        "        Trains the model for one epoch.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        train_loader : torch.utils.data.DataLoader\n",
        "            DataLoader for the training dataset.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            Average training loss for the epoch.\n",
        "        \"\"\"\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "        for data, target in train_loader:\n",
        "            data, target = data.to(self.device), target.squeeze(1).to(self.device)\n",
        "            self.optimizer.zero_grad()\n",
        "            output = self.model(data)\n",
        "            loss = self.criterion(output, target)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        return total_loss / len(train_loader)\n",
        "\n",
        "    def evaluate(self, val_loader):\n",
        "        \"\"\"\n",
        "        Evaluates the model on a validation dataset.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        val_loader : torch.utils.data.DataLoader\n",
        "            DataLoader for the validation dataset.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        tuple\n",
        "            A tuple containing:\n",
        "            - float: Average validation loss.\n",
        "            - float: Validation accuracy (0 to 1).\n",
        "        \"\"\"\n",
        "        self.model.eval()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for data, target in val_loader:\n",
        "                data, target = data.to(self.device), target.squeeze(1).to(self.device)\n",
        "                output = self.model(data)\n",
        "                loss = self.criterion(output, target)\n",
        "                total_loss += loss.item()\n",
        "                pred = output.argmax(dim=1)\n",
        "                correct += pred.eq(target).sum().item()\n",
        "                total += target.numel()\n",
        "        return total_loss / len(val_loader), correct / total"
      ],
      "metadata": {
        "id": "DIW6FopF4y70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### This code initializes the model configuration with the specified number of spectral bands and creates an instance of CorkOakTrainer. It then loads the pre-trained model weights from the designated .pth file and sets the model to evaluation mode. This prepares the model for making predictions on validation or test datasets."
      ],
      "metadata": {
        "id": "61Yw1X-VH2q7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model\n",
        "print(\"\\nLoading the model...\")\n",
        "config = ModelConfig(n_bands=4)\n",
        "trainer = CorkOakTrainer(config)\n",
        "# Saved model can be downloaded at https://github.com/domwelsh/quercus-detection/tree/main/trained_model\n",
        "trainer.model.load_state_dict(torch.load('/content/drive/MyDrive/Your_Folder/model.pth'))\n",
        "trainer.model.eval()"
      ],
      "metadata": {
        "id": "QkDQbMQG8Gv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Create input sequences base on satellite images\n"
      ],
      "metadata": {
        "id": "ygSTEZJpuFxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration of the workflow\n",
        "validation_folder = \"/content/drive/MyDrive/Your_Folder\"\n",
        "# Select a file from the validation_folder\n",
        "reference_raster_path = '/content/drive/MyDrive/Your_Folder/Add_a_name_Monthly_YYYY-MM.tif'\n",
        "band_names = ['NDWI', 'VARI', 'NDVI', 'rededge']\n",
        "\n",
        "# Identify the indices of the required bands\n",
        "print(\"Identifying band indices...\")\n",
        "band_indices = identify_band_indices(reference_raster_path, band_names)\n",
        "\n",
        "# Replace NaN with -9999 in the validation images\n",
        "print(\"Replacing NaN with -9999...\")\n",
        "processed_validation_folder = replace_nan_in_images(validation_folder)\n",
        "\n",
        "# Check statistics after replacing NaN\n",
        "print(\"\\nChecking band statistics...\")\n",
        "verify_band_statistics(processed_validation_folder, band_indices)\n",
        "\n",
        "# Generate sequences with the band indices\n",
        "print(\"\\nGenerating sequences...\")\n",
        "validation_sequences = generate_sequences_with_band_indices([processed_validation_folder], band_indices)\n",
        "print(f\"Shape of the generated sequences: {validation_sequences.shape}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "tZBqoYq_9DY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.4 Run the model\n"
      ],
      "metadata": {
        "id": "Rzn5e67hbRfc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Apply the Model**\n",
        "This code converts the validation sequences into a PyTorch tensor and feeds them into the trained model. It performs inference without computing gradients, generating the raw output predictions. The predictions are then processed to obtain the final class labels as NumPy arrays for further analysis."
      ],
      "metadata": {
        "id": "4JT46wGuIT5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the model with the specified function\n",
        "print(\"\\nApplying the model...\")\n",
        "validation_tensor = torch.tensor(validation_sequences, dtype=torch.float32)\n",
        "with torch.no_grad():\n",
        "    test_output = trainer.model(validation_tensor.to(trainer.device))\n",
        "    test_predictions = test_output.argmax(dim=1).cpu().numpy()"
      ],
      "metadata": {
        "id": "0qwmBwEJ-hgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.5 Output Calculation and Visualization"
      ],
      "metadata": {
        "id": "KgQz2gAgur_J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Validation and Visualization of Results**\n",
        "This code removes padding values (-9999) from the model's predictions, saves the filtered predictions as a GeoTIFF file, and visualizes both the original data and the model's predictions side by side. It ensures that only valid prediction data is retained, facilitates spatial analysis by saving predictions in GeoTIFF format, and provides visual confirmation of the model's performance through plotted images."
      ],
      "metadata": {
        "id": "tc6OBe8yImfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exclude padding values (-9999)\n",
        "valid_mask = (validation_sequences[0, 0, 0] != -9999)\n",
        "filtered_predictions = np.full_like(test_predictions[0], fill_value=-9999, dtype=np.int32)\n",
        "filtered_predictions[valid_mask] = test_predictions[0][valid_mask]\n",
        "\n",
        "# Save predictions as GeoTIFF\n",
        "def save_predictions_as_geotiff(predictions, reference_raster_path, output_path):\n",
        "    with rasterio.open(reference_raster_path) as ref_raster:\n",
        "        profile = ref_raster.profile\n",
        "        profile.update(dtype=rasterio.int32, count=1, nodata=-9999)\n",
        "\n",
        "        with rasterio.open(output_path, 'w', **profile) as dst:\n",
        "            dst.write(predictions, 1)\n",
        "\n",
        "output_raster_path = '/content/drive/MyDrive/Your_Folder/predictions.tif'\n",
        "save_predictions_as_geotiff(filtered_predictions, reference_raster_path, output_raster_path)\n",
        "print(f\"Predictions saved to: {output_raster_path}\")\n",
        "\n",
        "# Visualize the predictions\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(validation_sequences[0, 0, 0], cmap=\"gray\")\n",
        "plt.title(\"Original Data\")\n",
        "plt.colorbar()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(filtered_predictions, cmap=\"viridis\", vmin=0, vmax=1)\n",
        "plt.title(\"Model Predictions\")\n",
        "plt.colorbar()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uGIKXcxC-T6W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}